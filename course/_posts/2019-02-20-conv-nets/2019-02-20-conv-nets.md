---
title: "How Computers Can See and Other Ways Machines Can Think"
categories: ["sp19"]
authors: ['irenelt97', 'brandons209', 'ionlights']
description: >-
  "Ever wonder how Facebook can tell you which friends to tag in your photos or how Google automatically makes collages and animations for you? This lecture is all about that: We'll teach you the basics of computer vision  using convolutional neural networks so you can make your own algorithm to automatically analyze your visual data!"
---

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Classifying-Dog-Breeds-with-a-CNN-and-Transfer-Learning">Classifying Dog Breeds with a CNN and Transfer Learning<a class="anchor-link" href="#Classifying-Dog-Breeds-with-a-CNN-and-Transfer-Learning">&#182;</a></h1><h3 id="Ever-wondered-what-type-of-breed-that-cute-dog-is?">Ever wondered what type of breed that cute dog is?<a class="anchor-link" href="#Ever-wondered-what-type-of-breed-that-cute-dog-is?">&#182;</a></h3><p>Let's use the power of CNN's and transfer learning to find out!
The link to the slide deck is <a href="https://docs.google.com/presentation/d/1DmZ5SEkmaMfS6Q-vheb1X2ICZZPvBlWIi_4KP4yfA3U/edit?usp=sharing">here</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Download-and-Extract-the-Dataset">Download and Extract the Dataset<a class="anchor-link" href="#Download-and-Extract-the-Dataset">&#182;</a></h3><p>These commands will download the dataset of dog images to your collab instance/current directory. Once downloaded, the images are then unzipped. A script to download from google drive links is also needed to download pre-trained weights for our model later in the notebook.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>unzip dogImages.zip &gt; /dev/null
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget https://raw.githubusercontent.com/circulosmeos/gdown.pl/master/gdown.pl
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Examples-of-our-Data">Examples of our Data<a class="anchor-link" href="#Examples-of-our-Data">&#182;</a></h3><p>It is very important to see the type of data you are dealing with before anything else. Here is a simple function to load in an image and print it's dimensions. Let's see a few different images from our training set.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.image</span> <span class="k">as</span> <span class="nn">mpimg</span>                
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                        
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="k">def</span> <span class="nf">show_img</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">mpimg</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Image Shape: &quot;</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">show_img</span><span class="p">(</span><span class="s2">&quot;dogImages/train/003.Airedale_terrier/Airedale_terrier_00164.jpg&quot;</span><span class="p">)</span>
<span class="n">show_img</span><span class="p">(</span><span class="s2">&quot;dogImages/train/027.Bloodhound/Bloodhound_01904.jpg&quot;</span><span class="p">)</span>
<span class="n">show_img</span><span class="p">(</span><span class="s2">&quot;dogImages/train/048.Chihuahua/Chihuahua_03439.jpg&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="What-do-you-notice-about-each-of-these-images?">What do you notice about each of these images?<a class="anchor-link" href="#What-do-you-notice-about-each-of-these-images?">&#182;</a></h3><p>The shape of each image is w.r.t. (width, height, num_channels). Number of channels in this case is three, one channel for Red, Green, and Blue.</p>
<p>It seems though that each of these images has a different resolution! That is an issue, as the network can only take in a fixed image size as input. When the images are loaded in, they will need to be resized according to an input dimension that we can set. This is easy to do, but make sure to read up on how resizing works for each library. You usually want to preserve the aspect ratio so you don't stretch or distort the image.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Includes">Includes<a class="anchor-link" href="#Includes">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># for one-hot encoding labels</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="k">import</span> <span class="n">np_utils</span>
<span class="c1"># for loading in file paths and labels</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_files</span>  
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">glob</span> <span class="k">import</span> <span class="n">glob</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-in-pretrained-InceptionV3-network">Load in pretrained InceptionV3 network<a class="anchor-link" href="#Load-in-pretrained-InceptionV3-network">&#182;</a></h3><p>For this project, we will use a pretrained model called InceptionV3, trained on <a href="http://www.image-net.org/">imagenet</a> dataset. Imagenet is a huge collection of small images with over 1000 different classes to predict. This gives the advantage of using a model that already has some learned knowledge, then <strong>fine tuning</strong> so it learns the features of our dataset. Check out the paper on InceptionV3 at the end of this notebook. This is especially good in our case, as Imagenet contains a variety of dogs, so the network has seen dogs before.</p>
<p>After the workshop, try using other pretrained models that come with Keras. You can check them out <a href="https://keras.io/applications/">here</a> (InceptionResNetV2 or VGG16/VGG19 might be good models to try next). Make sure to check what the default image sizes for the network are!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.applications.inception_v3</span> <span class="k">import</span> <span class="n">InceptionV3</span>
<span class="c1">#from keras.applications.resnet50 import ResNet50</span>
<span class="c1">#from keras.applications.vgg16 import VGG16</span>
<span class="c1">#from keras.applications.inception_resnet_v2 import InceptionResNetV2</span>
<span class="c1">#from keras.applications.vgg19 import VGG19</span>

<span class="c1"># include_top=False means that we only load in the convolutional layers of the network, not the classifier layers</span>
<span class="c1"># replace this with a different model if you want to try another model</span>
<span class="n">inception_model</span> <span class="o">=</span> <span class="n">InceptionV3</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">,</span> <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Define-functions-to-load-images">Define functions to load images<a class="anchor-link" href="#Define-functions-to-load-images">&#182;</a></h3><p>Usually, when dealing with image data, you need a lot of disk space and RAM/VRAM space to load the images, as each image is quite big. Because of this, it would be inefficient to load them in all at once, taking up lots of RAM and VRAM when training. Instead, we can use a <strong>generator</strong> that will load images in batches for us on the fly. Python has its own generator that can be used using the <strong>yield</strong> operator, but that cannot be multithreaded with Keras. Instead, we define a class for our generator that inherits from Keras' Sequence class.</p>
<p>To do so, the functions <code>__init__()</code>, <code>__len__()</code>, and <code>__getitem(index)__</code> must be defined. The len() functions returns how many batches are in the generator, and the getitem() defines how the images are processed before being returned to the generator. Read up more on Keras' generator <a href="https://keras.io/utils/">here</a>.</p>
<p>With this, some helper functions are defined for the generator to use. Note that we want an array of images, so the entire image batch will have a shape of (num_images, w, h, num_channels).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="k">import</span> <span class="n">image</span> <span class="k">as</span> <span class="n">image_processor</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="k">import</span> <span class="n">Sequence</span>
<span class="c1"># needed because of truncated image error when loading train images:</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="k">import</span> <span class="n">ImageFile</span>
<span class="n">ImageFile</span><span class="o">.</span><span class="n">LOAD_TRUNCATED_IMAGES</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># Loads in a single image from path and resizes it to img_dim</span>
<span class="k">def</span> <span class="nf">load_image_from_path</span><span class="p">(</span><span class="n">img_path</span><span class="p">,</span> <span class="n">img_dim</span><span class="p">):</span>
    <span class="c1"># loads RGB image as PIL.Image.Image type</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">image_processor</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">img_path</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="n">img_dim</span><span class="p">)</span>
    <span class="c1"># convert PIL.Image.Image type to 3D tensor with shape (w, h, 3)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">image_processor</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="c1"># convert 3D tensor to 4D tensor with shape (1, w, h, 3) and return 4D tensor</span>
    <span class="c1"># this extra dimension represents the number of images in this array, which in this case is just 1 </span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># loads in all images in the directory given with img_dim</span>
<span class="k">def</span> <span class="nf">load_directory</span><span class="p">(</span><span class="n">img_paths</span><span class="p">,</span> <span class="n">img_dim</span><span class="p">):</span>
    <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">load_image_from_path</span><span class="p">(</span><span class="n">img_path</span><span class="p">,</span> <span class="n">img_dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">img_path</span> <span class="ow">in</span> <span class="n">img_paths</span><span class="p">]</span>
    <span class="c1"># loads in all images in img_path, then concatenates them along axis 0</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

<span class="c1"># loads in paths for all of the data, only with class label for each image</span>
<span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="c1"># from sklearn: returns filenames with a label 0-133 for each class</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">load_files</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">dog_files</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;filenames&#39;</span><span class="p">])</span>
    <span class="c1"># one-hot encode labels</span>
    <span class="n">dog_targets</span> <span class="o">=</span> <span class="n">np_utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]),</span> <span class="mi">133</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dog_files</span><span class="p">,</span> <span class="n">dog_targets</span>

<span class="c1"># defines the sequence generator class for the dog images</span>
<span class="k">class</span> <span class="nc">Dog_Sequence_Generator</span><span class="p">(</span><span class="n">Sequence</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_directory</span><span class="p">,</span> <span class="n">img_dim</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="c1"># load dog files with labels:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dog_files</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dog_targets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">image_directory</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">img_dim</span> <span class="o">=</span> <span class="n">img_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># returns number of batches in this generator</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dog_files</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="c1">#get image paths for current batch</span>
        <span class="n">batch_images</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dog_files</span><span class="p">[</span><span class="n">idx</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="p">:</span> <span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="c1">#load images into memory</span>
        <span class="n">batch_images</span> <span class="o">=</span> <span class="n">load_directory</span><span class="p">(</span><span class="n">batch_images</span><span class="p">,</span> <span class="n">img_dim</span><span class="p">)</span>
        <span class="c1">#get image targets</span>
        <span class="n">batch_targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dog_targets</span><span class="p">[</span><span class="n">idx</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="p">:</span> <span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">batch_images</span><span class="p">,</span> <span class="n">batch_targets</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-generators-for-the-data">Create generators for the data<a class="anchor-link" href="#Create-generators-for-the-data">&#182;</a></h3><p>The default image size of InceptionV3 is (299, 299, 3) for imagenet pretrained weights. The batch size is also defined, which in this case I have chosen 8. If you get OOM (out of memory) errors when training, reduce the batch size.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">img_dim</span> <span class="o">=</span> <span class="p">(</span><span class="mi">299</span><span class="p">,</span> <span class="mi">299</span><span class="p">)</span><span class="c1">#for inceptionv3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>

<span class="c1"># generators for each type of data</span>
<span class="n">train_gen</span> <span class="o">=</span> <span class="n">Dog_Sequence_Generator</span><span class="p">(</span><span class="s1">&#39;dogImages/train&#39;</span><span class="p">,</span> <span class="n">img_dim</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">valid_gen</span> <span class="o">=</span> <span class="n">Dog_Sequence_Generator</span><span class="p">(</span><span class="s1">&#39;dogImages/valid&#39;</span><span class="p">,</span> <span class="n">img_dim</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">test_gen</span> <span class="o">=</span> <span class="n">Dog_Sequence_Generator</span><span class="p">(</span><span class="s1">&#39;dogImages/test&#39;</span><span class="p">,</span> <span class="n">img_dim</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

<span class="c1"># get label names</span>
<span class="n">dog_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">20</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;dogImages/train/*/&quot;</span><span class="p">))]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of images: training: </span><span class="si">{}</span><span class="s2">, validation: </span><span class="si">{}</span><span class="s2">, testing: </span><span class="si">{}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;dogImages/train/*/*&quot;</span><span class="p">)),</span> <span class="nb">len</span><span class="p">(</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;dogImages/valid/*/*&quot;</span><span class="p">)),</span> 
                                                                                <span class="nb">len</span><span class="p">(</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;dogImages/test/*/*&quot;</span><span class="p">))))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of batches: training: </span><span class="si">{}</span><span class="s2">, validation: </span><span class="si">{}</span><span class="s2">, testing: </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_gen</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_gen</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_gen</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model:">Model:<a class="anchor-link" href="#Model:">&#182;</a></h3><p>Now it is time to define the model. We already created the first part of our model, but it does not have a classifier for the images. Here we will add the last few convolutional/pooling layers, and our dense layers for classification.</p>
<p>First off, for Keras, <a href="https://keras.io/layers/convolutional/">Convolutional2D</a> layers can be created as:</p>
<div class="highlight"><pre><span></span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
<p>With networks dealing with image data, it is a good idea to use ReLu or LeakyReLu activation functions for all of your layers. These activation functions have been shown to get better results. Read more about them <a href="https://cs231n.github.io/neural-networks-1/#actfun">here</a>.</p>
<p>Padding determines whether to "pad" the edges of images with zeros when the filter goes past the image while performing the convolution. Usually, filters don't perfectly fit in an image. So, with padding as "valid", the images are not padded with zeros and the kernel stops from going past the imaged edge. This can help with reducing noise in data, as those zeros are meaningless when padding. However, the features close to the edges of images are also ignored, so that can cause the network to not learn certain features. Padding with "same" pads edges with zeros.</p>
<p><a href="https://keras.io/layers/pooling/">Pooling</a> layers are defined as:</p>
<div class="highlight"><pre><span></span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">)</span>
<span class="n">GlobalAveragePooling2D</span><span class="p">()</span>
</pre></div>
<p>Global Average Pooling averages the features of previous convolutional layers to one dimension, that is stretched out along the channels dimension we seen have before. For example, if the output of the last convolutional layer was (20, 16, 16, 128), then those are averaged down to something like (20, 512). For our purpose, this layer will be used to average the convolutional layers down to an input shape that a dense layer can take in.</p>
<p>Here is something you may of not seen before, and that is Keras' <a href="https://keras.io/getting-started/functional-api-guide/">functional</a> model API. This provides a bit more flexibility when building models than Sequential does. We need this in order to have our inputs go through the pretrained model created before and output through the classifier network we will build now. That part is taken care of for you here, so we will build the model like we have before with the Sequential API.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">GlobalAveragePooling2D</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">Model</span>

<span class="n">output_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="c1">### Put Model Here ###</span>



<span class="c1">######################</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">inception_model</span><span class="o">.</span><span class="n">output</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">output_model</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">133</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">out</span><span class="p">)</span>

<span class="n">inception_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inception_model</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
<span class="n">output_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="c1"># inception_model.summary()# uncomment to see inception_model</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-Compiliation">Model Compiliation<a class="anchor-link" href="#Model-Compiliation">&#182;</a></h3><p>So for this model, I used RMSprop to train the network. The Adam optimizer you have seen before might give better results, so try that on your own! For the loss function, categorical_crossentropy is used since we are using one-hot encoded labels.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras</span> <span class="k">import</span> <span class="n">optimizers</span> <span class="k">as</span> <span class="n">opt</span> 
<span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">inception_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Training">Training<a class="anchor-link" href="#Training">&#182;</a></h3><p>Since we are using Keras generators for our data, our fit function is now fit_generator. Is still uses all the same parameters as the regular fit function though. We also define the number of works, which is the number of threads to run for processing the data in our generator. In collab, we only have two cores, but up this number if you are running it on your own computer and have the extra threads to spare.</p>
<p>For callbacks, we have the checkpointer callback for our weights, an EarlyStopping callback to stop the model training early when validation loss does not improve for a defined number of epochs, and a reduce learning rate callback, which reduces the learn rate by a specified factor if the validation loss does not improve after a defined number of epochs. This is why epochs is set to 300, because the model will end early once it converges.</p>
<p>This model would take a long time to train in collab, even with the GPU instance. So let's download and load in weights that were already trained on before.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="k">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">EarlyStopping</span><span class="p">,</span> <span class="n">ReduceLROnPlateau</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">num_workers</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s1">&#39;weights.best.transfer.inception.test.hdf5&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">early_stop</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">reduce_lr</span> <span class="o">=</span>  <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cooldown</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_lr</span><span class="o">=</span><span class="mf">1e-14</span><span class="p">)</span>
                           
<span class="n">inception_model</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span><span class="n">train_gen</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">valid_gen</span><span class="p">,</span>
                              <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                              <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">,</span> <span class="n">early_stop</span><span class="p">,</span> <span class="n">reduce_lr</span><span class="p">],</span> <span class="n">workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-best-validation-loss-weights">Load best validation loss weights<a class="anchor-link" href="#Load-best-validation-loss-weights">&#182;</a></h3><p>This will download the weight file for the model we created from google drive.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>chmod +x gdown.pl
<span class="o">!</span>./gdown.pl https://drive.google.com/file/d/1EexGOGyFaqVWshRUaZdXe5y3RFWXQlzr/view weights.inception.soln.hdf5
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># comment first line and uncommment second line if loading in your own weights</span>
<span class="n">inception_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;weights.inception.soln.hdf5&#39;</span><span class="p">)</span>
<span class="c1">#inception_model.load_weights(&#39;weights.best.transfer.inception.test.hdf5&#39;)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Test-model-accuracy">Test model accuracy<a class="anchor-link" href="#Test-model-accuracy">&#182;</a></h3><p>Again, we use evaluate_generator instead of evaluate function since we have a generator.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">metrics</span> <span class="o">=</span> <span class="n">inception_model</span><span class="o">.</span><span class="n">evaluate_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test loss: </span><span class="si">{0:.4f}</span><span class="s1">, Test accuracy: </span><span class="si">{1:.2f}</span><span class="s1">%&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Let's-see-some-dogs!">Let's see some dogs!<a class="anchor-link" href="#Let's-see-some-dogs!">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="n">image_path</span><span class="p">):</span>
    <span class="n">display_img</span> <span class="o">=</span> <span class="n">mpimg</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Hello!&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">display_img</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">input_img</span> <span class="o">=</span> <span class="n">load_image_from_path</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="n">img_dim</span><span class="p">)</span>
    <span class="n">pred_class</span> <span class="o">=</span> <span class="n">dog_names</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">inception_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_img</span><span class="p">))]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;You are a </span><span class="si">{}</span><span class="s2"> dog!! </span><span class="si">{}</span><span class="s2">/10&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pred_class</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">classify</span><span class="p">(</span><span class="s2">&quot;dogImages/test/008.American_staffordshire_terrier/American_staffordshire_terrier_00538.jpg&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What's-next?">What's next?<a class="anchor-link" href="#What's-next?">&#182;</a></h2><p>If you have a NVIDIA GPU at home, try training this model on there. It should not take too long on something like a 1060 or above. Use different pre-trained models, classifier networks, and optimizers to get better results. This is extremely important to do if you want to build up an intuition on creating better models.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="References">References<a class="anchor-link" href="#References">&#182;</a></h2><ul>
<li><a href="https://arxiv.org/abs/1512.00567">InceptionV3 Paper</a></li>
<li><a href="https://cs231n.github.io/transfer-learning/">Transfer Learning</a></li>
</ul>

</div>
</div>
</div>
 


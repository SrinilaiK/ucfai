---
layout: meeting
title: A Walk Through the Random Forest
date: 2019-09-25
authors:
    - jarviseq
    
categories: ['fa19']
tags: ['random-forests', 'svms', 'weak-models', 'non-nn']
description: >-
    In this lecture, we explore powerful yet lightweight models that are often  overlooked. We will see the power of combining multiple simple models together and how they can yield amazing results. You won't believe how easy it is to  classify with just a line!
---
{% raw %}  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

  

  <!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration -->
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="k">import</span> <span class="n">Path</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">&quot;/kaggle/input&quot;</span><span class="p">):</span>
    <span class="n">DATA_DIR</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;/kaggle/input&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;We don&#39;t know this machine.&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Overview">Overview<a class="anchor-link" href="#Overview">&#182;</a></h2><p>Before getting going on more complex examples, 
we're going to take a look at a very simple example using the Iris Dataset.</p>
<p>The final example deals with credit card fraud, 
and how to identify if fraud is taking place based a dataset of over 280,000 entries.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Importing the important stuff</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">matthews_corrcoef</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Iris-Data-Set">Iris Data Set<a class="anchor-link" href="#Iris-Data-Set">&#182;</a></h2><p>This is a classic dataset of flowers. The goal is to have the model classify the types of flowers based on 4 factors. 
Those factors are sepal length, sepal width, petal length, and petal width, which are all measured in cm. 
The dataset is very old in comparison to many of the datasets we use, coming from a 
<a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-1809.1936.tb02137.x">1936 paper about taxonomy</a>.</p>
<h3 id="Getting-the-Data-Set">Getting the Data Set<a class="anchor-link" href="#Getting-the-Data-Set">&#182;</a></h3><p>Sklearn has the dataset built into the the library, so getting the data will be easy.
Once we do that, we'll do a test-train split.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_iris</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Making-the-Model">Making the Model<a class="anchor-link" href="#Making-the-Model">&#182;</a></h3><p>Making and Random Forests model is very easy, taking just two lines of code! 
Training times can take a second, but in this example is small so the training time is minimal.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="n">trees</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trees</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>sklearn has a few parameters that we can tweak to tune our model. 
We won't be going into those different parameters in this notebook, 
but if you want to give it a look, 
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">here is the documentation.</a></p>
<h3 id="We-need-to-Figure-out-how-well-this-model-does">We need to Figure out how well this model does<a class="anchor-link" href="#We-need-to-Figure-out-how-well-this-model-does">&#182;</a></h3><p>There are a few ways we are going to test for accuracy using a Confusion Matrix and Matthews Correlation Coefficient .</p>
<h4 id="Confusion-Matrix">Confusion Matrix<a class="anchor-link" href="#Confusion-Matrix">&#182;</a></h4><p>A Confusion Matrix shows us where the model is messing up. Below is an example from dataschool.io. The benefit of a confusion matrix is that it is a very easy way to visualise the performance of the model.</p>
<p><img src="https://www.dataschool.io/content/images/2015/01/confusion_matrix_simple2.png" alt="alt text"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">trees</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Matthews-correlation-coefficient">Matthews correlation coefficient<a class="anchor-link" href="#Matthews-correlation-coefficient">&#182;</a></h4><p>This is used to find the quality of binary classification. 
It is based on the values found in the Confusion Matrix and tries to take those values and boil it down to one number. 
It is generally considered one of the better measures of quality for classification. 
MCC does not rely on class size, so in cases where we have very different class sizes, 
we can get a realiable measure of how well it did.</p>
<p>Matthews correlation coefficient ranges from -1 to 1. 
-1 represents total disagreement between the prediction and the observation, 
while 1 represents prefect prediction. 
In other words, the closer to 1 we get the better the model is considered.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">matthews_corrcoef</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Now,-what-about-SVMs?">Now, what about SVMs?<a class="anchor-link" href="#Now,-what-about-SVMs?">&#182;</a></h3><p>We want to see how well SVMs can work on the Iris, so let's see it in action.</p>
<p>First, let's define the models; one for linear, ploy and rbf.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># SVM regularization parameter, we&#39;ll keep it simple for now</span>
<span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span> 

<span class="n">models</span> <span class="o">=</span> <span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">),</span>
          <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">),</span>
          <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So you know what the parameters mean:</p>
<ul>
<li>degree refers to the degree of the polynomial</li>
<li>gamma refer to the influence of a single training example reaches<blockquote><ul>
<li>with low values meaning ‘far’ and high values meaning ‘close’</li>
</ul>
</blockquote>
</li>
</ul>
<p>Once we have the models defined, let's train them!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span> <span class="k">for</span> <span class="n">clf</span> <span class="ow">in</span> <span class="n">models</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we are see how the confusion matrices look like:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">clf</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The confusion matrix is all nice and dandy, 
but let's check out what the Matthews Coefficient has to say about our models.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">clf</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">matthews_corrcoef</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That wasn't too bad was it? 
Both Random Forests and SVMs are very easy models to implement,
and its low training times means that the model can be used without the overheads associated with neural networks, 
which we will learn more about next week.</p>
<h2 id="Credit-Card-Fraud-Dataset">Credit Card Fraud Dataset<a class="anchor-link" href="#Credit-Card-Fraud-Dataset">&#182;</a></h2><p>As always, we are going to need a dataset to work on!
Credit card fraud detection is a serious issue, and as such is something that data scientists have looked into. This dataset is from a Kaggle competition with over 2,000 Kernals based on it. Let's see how well Random Forests can do with this dataset!</p>
<p>Lets read in the data and use <em>.info()</em> to find out some meta-data</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATA_DIR</span> <span class="o">/</span> <span class="s2">&quot;train.csv&quot;</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>What's going on with this V stuff?
Credit Card information is a bit sensitive, and as such raw information had to be obscured in some way to protect that information.</p>
<p>In this case, the data provider used a method know as PCA transformation to hide those features that would be considered sensitive. 
PCA is a very useful technique for dimension reduction. 
For now, know that this technique allows us to take data and transform it in a way that maintains the patterns in that data.</p>
<p>If you are interested in learning more about PCA, 
<a href="https://towardsdatascience.com/a-step-by-step-explanation-of-principal-component-analysis-b836fb9c97e2">Consider checking out this article</a>. 
Unfortunately, there is a lot that we want to cover in Core and not enough time to do all of it. :(</p>
<p>Next, let's get some basic statistical info from this data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Some-important-points-about-this-data">Some important points about this data<a class="anchor-link" href="#Some-important-points-about-this-data">&#182;</a></h3><p>For most of the features, there is not a lot we can gather since it's been obscured with PCA. 
However there are three features that have been left in for us to see.</p>
<h4 id="1.-Time">1. Time<a class="anchor-link" href="#1.-Time">&#182;</a></h4><p>Time is the amount of time from first transaction in seconds. 
The max is 172792, so the data was collected for around 48 hours.</p>
<h4 id="2.-Amount">2. Amount<a class="anchor-link" href="#2.-Amount">&#182;</a></h4><p>Amount is the amount that the transaction was for. 
The denomination of the transactions was not given, so we're going to be calling them "Simoleons" as a place holder. 
Some interesting points about this feature is the STD, or standard deviation, which is 250§. That's quite large, 
but makes sense when the min and max are 0§ and 25,691§ respectively. 
There is a lot of variance in this feature, which is to be expected. The 75% amount is only in 77§, 
which means that the whole set skews to the lower end.</p>
<h4 id="3.-Class">3. Class<a class="anchor-link" href="#3.-Class">&#182;</a></h4><p>This tells us if the transaction was fraud or not. 0 is for no fraud, 1 if it is fraud. 
If you look at the mean, it is .001727, which means that only .1727% of the 284,807 cases are fraud. 
There are only 492 fraud examples in this data set, so we're looking for a needle in a haystack in this case.</p>
<p>Now that we have that out of the way, let's start making this model! We need to split our data first</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>

<span class="c1"># sklearn requires a shape with dimensions (N, 1), </span>
<span class="c1"># so we expand dimensions of x and y to put a 1 in the second dimension</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;X shape: </span><span class="si">{X.shape}</span><span class="s2"> Y shape: </span><span class="si">{Y.shape}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Some-Points-about-Training">Some Points about Training<a class="anchor-link" href="#Some-Points-about-Training">&#182;</a></h3><p>With Random Forest and SVMs, training time is very quick, so we can finish training the model in realitively short order, 
even when our dataset contains 284,807 entries. This is done without the need of GPU acceleration, 
which Random Forests cannot take advantage of.</p>
<p>The area is left blank, 
but there's examples on how to make the models earlier in the notebook that can be used as an example if you need it. 
What model and the parameters you choose are up to you, so have fun!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Make the magic happen!</span>
<span class="c1"># https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATA_DIR</span> <span class="o">/</span> <span class="s2">&quot;test.csv&quot;</span><span class="p">)</span>

<span class="c1"># to expedite things: pass `n_jobs=-1` so you can run across all available CPUs</span>
<span class="c1">### BEGIN SOLUTION</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="c1">### END SOLUTION</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Submitting-your-Solution">Submitting your Solution<a class="anchor-link" href="#Submitting-your-Solution">&#182;</a></h3><p>To submit your solution to kaggle, you'll need to save you data.</p>
<p>Luckily, we got the code you need to do that below.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">


<div class="inner_cell">
    <div class="input_area">
        <div class=" highlight hl-ipython3"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Id&#39;</span><span class="p">:</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="s1">&#39;Class&#39;</span><span class="p">:</span> <span class="n">predictions</span><span class="p">})</span>

<span class="n">predictions</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;submission.csv&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Id&#39;</span><span class="p">,</span> <span class="s1">&#39;Class&#39;</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Thank-You">Thank You<a class="anchor-link" href="#Thank-You">&#182;</a></h2><p>We hope that you enjoyed being here today.</p>
<p>Please fill out <a href="https://docs.google.com/forms/d/e/1FAIpQLSemUFE7YNrnKYT-KBUJcsWbmNkBIj_1aT0mtw3LszJLOMAXLA/viewform?usp=sf_link">this questionaire</a> so we can get some feedback about tonight's meeting.</p>
<p>We hope to see you here again next week for our Core meeting on <em>Neural Networks</em>.</p>
<h3 id="Vevu-en-Virtu">Vevu en Virtu<a class="anchor-link" href="#Vevu-en-Virtu">&#182;</a></h3>
</div>
</div>
</div>
  
 


{% endraw %}